{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Transforming the OpenEI original dataset into usable data files\n",
    "\n",
    "This notebook shows how to transform the original (full) [OpenEI dataset](https://data.openei.org/submissions/153)\n",
    "into the set of binary data files (.npz) in the `data/openei` folder, which\n",
    "can be loaded by our code.\n",
    "\n",
    "It serves several purposes:\n",
    "\n",
    "1. Transparency: document what is done, so that researchers can agree (or not).\n",
    "2. Reproducibility: allow researchers to re-create the files if necessary,\n",
    "   including with some tweaks (e.g., changing the max_storage value).\n",
    "3. Example: this notebook could serve as an example to take inspiration from,\n",
    "   when adapting a new dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1. Download files\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The data is in 2 parts: commercial and residential.\n",
    "!curl -o commercial.tar.zip https://data.openei.org/files/153/COMMERCIAL_LOAD_DATA_E_PLUS_OUTPUT.tar.zip\n",
    "!curl -o residential.zip https://data.openei.org/files/153/RESIDENTIAL_LOAD_DATA_E_PLUS_OUTPUT.zip"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2. Uncompress data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "household_filename = 'USA_AK_Anchorage.Intl.AP.702730_TMY3_BASE.csv'\n",
    "office_filename = 'RefBldgSmallOfficeNew2004_v1.3_7.1_8A_USA_AK_FAIRBANKS.csv'\n",
    "school_filename = 'RefBldgPrimarySchoolNew2004_v1.3_7.1_8A_USA_AK_FAIRBANKS.csv'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# We want a single file, we do not need the full archive content.\n",
    "# `-j`: junk paths, does not re-create the archive hierarchy.\n",
    "# Only the \"RES.../$household_filename\" file will be extracted, to the current\n",
    "# directory.\n",
    "!unzip -j residential.zip \"RESIDENTIAL_LOAD_DATA_E_PLUS_OUTPUT/BASE/\"$household_filename\n",
    "\n",
    "# It is a bit harder with the commercial archive, as it is a ZIP archive of\n",
    "# several parts (part1, part2, ...) of TAR.GZ archives.\n",
    "!unzip commercial.tar.zip\n",
    "!tar xzf COMMERCIAL_LOAD_DATA_E_PLUS_OUTPUT.part1.tar.gz --strip-components=1 \"USA_AK_Anchorage.Intl.AP.702730_TMY3/\"$office_filename\n",
    "!tar xzf COMMERCIAL_LOAD_DATA_E_PLUS_OUTPUT.part1.tar.gz --strip-components=1 \"USA_AK_Anchorage.Intl.AP.702730_TMY3/\"$school_filename"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3. Parse data\n",
    "\n",
    "We want to build 3 agent profiles:\n",
    "\n",
    "- a Household (corresponding to the `household_filename` CSV file);\n",
    "- an Office (`office_filename` CSV file);\n",
    "- a School (`school_filename` CSV file).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def parse_data(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    # We need to split Date and Time (just in case we want to aggregate)\n",
    "    df[['Date', 'Time']] = df['Date/Time'].str.split('  ', n=1, expand=True, regex=False)\n",
    "    # Transform Electricity from kW to W, and round to integer\n",
    "    df['Electricity (Wh)'] = df['Electricity:Facility [kW](Hourly)'] * 1000\n",
    "    df['Electricity (Wh)'] = df['Electricity (Wh)'].astype(int)\n",
    "    # Keep only the `Date/Time` and `Electricity (Wh)` columns\n",
    "    df = df[['Date', 'Time', 'Electricity (Wh)']]\n",
    "    return df\n",
    "\n",
    "def annual_to_daily(df):\n",
    "    # To have a single datapoint per hour, we want to aggregate all days.\n",
    "    # So we group by `Time` (the hour), and take the average.\n",
    "    return df['Electricity (Wh)'].groupby('Time')['Electricity (Wh)'].agg('mean')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_household = parse_data(household_filename)\n",
    "df_office = parse_data(office_filename)\n",
    "df_school = parse_data(school_filename)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4. Write data profiles\n",
    "\n",
    "Now that we have the profiles' needs (electricity consumed each hour), we\n",
    "will write the profiles to data files, which are NumPy archive (npz files)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def write_profile(name, needs, max_storage, action_limit):\n",
    "    filepath = f'../data/openei/{name}'\n",
    "    np.savez(filepath,\n",
    "             needs=needs,\n",
    "             action_limit=action_limit,\n",
    "             max_storage=max_storage)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Residential - Annual profile\n",
    "write_profile(\n",
    "    'profile_residential_annually.npz',\n",
    "    df_household['Electricity (Wh)'],\n",
    "    500,\n",
    "    2500  # This is slightly higher than `df_household['Electricity (Wh)'].max()`\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Residential - Daily profile\n",
    "write_profile(\n",
    "    'profile_residential_daily.npz',\n",
    "    annual_to_daily(df_household),\n",
    "    500,\n",
    "    2000\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Office - Annual profile\n",
    "write_profile(\n",
    "    'profile_office_annually.npz',\n",
    "    df_office['Electricity (Wh)'],\n",
    "    2500,\n",
    "    14100\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Office - Daily profile\n",
    "write_profile(\n",
    "    'profile_office_daily.npz',\n",
    "    annual_to_daily(df_office),\n",
    "    2500,\n",
    "    11000\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# School - Annual profile\n",
    "write_profile(\n",
    "    'profile_school_annually.npz',\n",
    "    df_school['Electricity (Wh)'],\n",
    "    10_000,\n",
    "    205_000\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# School - Daily profile\n",
    "write_profile(\n",
    "    'profile_school_daily.npz',\n",
    "    annual_to_daily(df_school),\n",
    "    10_000,\n",
    "    125_000\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
